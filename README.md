# Awesome Trustworthy Retrieval Augmented Generation (RAG)
[![Awesome](https://awesome.re/badge.svg)](https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation/blob/main/LICENSE)
![](https://img.shields.io/badge/PRs-Welcome-red) 

> "The simple believes everything, but the prudent gives thought to his steps."

üôå This repository collects papers investigating the trustworthiness of retrieval augmented generation.

üòé Welcome to recommend missing papers through **`Adding Issues`** or **`Pull Requests`**. 

<!-- Details of summary and classification of papers are shown in [wiki](https://github.com/zjukg/KG-LLM-Papers/wiki). -->

## üîî News
- **`2024-06` We create this repository to maintain a paper list on `Trustworthiness of the LLM Retrieval Augmented Generation paradigm`.**

<!--
*Todo:*
1. - [ ] `Fine-grained classification of papers`
2. - [ ] `Update paper project / code`
3. - [ ] `Wiki page for brief paper introduction`
-->
   
## Content


  
- [üìú Papers](#papers)
  - [üìù Surveys](#surveys)
    - [RAG](#rag)
    - [LLM Trustworthiness](#llm-trustworthiness)
    - [RAG Trustworthiness](#rag-trustworthiness)
  - [üîí Privacy](#privacy)
  - [üîß Reliability](#reliability)
  - [üí™ Robustness](#robustness)
  - [‚õ® Safety](#safety)
  - [‚öñÔ∏è Fairness](#fairness)
  - [üìñ Explainability](#explainability)
  - [ü§ñ Others](#others)
---
##  Papers

### Surveys
#### RAG
- \[[arxiv](https://arxiv.org/abs/2312.10997)\]\[[Github](https://github.com/Tongji-KGLLM/RAG-Survey)\] Retrieval-Augmented Generation for Large Language Models: A Survey. `2024.03`
- \[[arxiv](https://arxiv.org/abs/2405.07437)\] Evaluation of Retrieval-Augmented Generation: A Survey. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2311.07914)\] Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey. `2023.11`
- \[[arxiv](https://arxiv.org/abs/2310.07521)\] Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity. `2023.10`
- \[[arxiv](https://arxiv.org/pdf/2306.11489.pdf)\] ChatGPT is not Enough: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. `2023.06`
- \[[arxiv](https://arxiv.org/abs/2211.05994)\] A Survey of Knowledge-Enhanced Pre-trained Language Models. `2023.05`
- \[[Paper](https://arxiv.org/abs/2302.07842)\] Augmented Language Models: a Survey. `2023.02`
#### LLM Trustworthiness
- \[[arxiv](https://arxiv.org/abs/2306.11698)\]\[[Website](https://decodingtrust.github.io)\] DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2304.08979)\] In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. `2023.04`
- \[[arxiv](https://arxiv.org/abs/2303.00293)\] How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks. `2023.03`
- \[[Paper](https://arxiv.org/abs/2210.09150)\] \[[Github](https://github.com/NoviScl/GPT3-Reliability)\] Prompting GPT-3 To Be Reliable. `2022.10`
#### RAG Trustworthiness
- \[[arxiv](https://arxiv.org/pdf/2409.10102)\] Trustworthiness in Retrieval-Augmented Generation Systems: A Survey. `2024.09`

### Privacy 
- \[[arxiv](https://arxiv.org/abs/2411.01705)\] Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors. `2024.11`
- \[[arxiv](https://arxiv.org/abs/2411.14110)\] RAG-Thief: Scalable Extraction of Private Data from Retrieval-Augmented Generation Applications with Agent-based Attacks. `2024.11`
- \[[arxiv](https://arxiv.org/abs/2410.20142)\] Mask-based Membership Inference Attacks for Retrieval-Augmented Generation. `2024.10`
- \[[arxiv](https://arxiv.org/pdf/2405.20485)\] Phantom: General Trigger Attacks on Retrieval Augmented Language Generation. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2409.08045)\] Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking. `2024.09`
- \[[arxiv](https://arxiv.org/abs/2405.20446)\] Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2406.14773)\] Mitigating the Privacy Issues in Retrieval-Augmented Generation (RAG) via Pure Synthetic Data. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2305.14888)\] Privacy Implications of Retrieval-Based Language Models. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2402.16893)\] The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG). `2024.02`


### Reliability
- \[[arxiv](https://arxiv.org/pdf/2307.04642)\] TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction. `2024.04`
- \[[arxiv](https://proceedings.neurips.cc/paper_files/paper/2022/file/8a0d3ae989a382ce6e50312bc35bf7e1-Paper-Conference.pdf)\] Unsupervised Cross-Task Generalization via Retrieval Augmentation. `2022.04`
- \[[arxiv](https://arxiv.org/pdf/2009.08553)\] Generation-Augmented Retrieval for Open-Domain Question Answering. `2021.05`
- \[[arxiv](https://arxiv.org/abs/2404.04287)\] CONFLARE: CONFormal LArge language model REtrieval. `2024.04`

### Robustness
- \[[arxiv](https://arxiv.org/abs/2406.00944)\] Unveil the Duality of Retrieval-Augmented Generation: Theoretical Analysis and Practical Solution. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2405.20978)\]  Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2405.15556)\] Certifiably Robust RAG against Retrieval Corruption. `2024.05`
- \[[ICLR](https://openreview.net/forum?id=ZS4m74kZpH)\] Making Retrieval-Augmented Language Models Robust to Irrelevant Context. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2403.14952)\] Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation. `2024.03`
- \[[Paper](https://openreview.net/pdf?id=XwnABAdH5y)\] Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning. `2023.07`

### Safety 
- \[[arxiv](https://arxiv.org/pdf/2402.07867)\] PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models `2024.08`
- \[[arxiv](https://arxiv.org/pdf/2406.00083v1)] BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models. `2024.06`
- \[[arxiv](https://arxiv.org/html/2406.18122v1)\] Poisoned LangChain: Jailbreak LLMs by LangChain. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2402.08416)\] Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2402.13532)\] Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2310.19156)\] Poisoning Retrieval Corpora by Injecting Adversarial Passages. `2023.10` 

### Fairness
- \[[arxiv](https://arxiv.org/abs/2305.19329)] Mitigating Test-Time Bias for Fair Image Retrieval. `2023.05`
- \[[arxiv](https://arxiv.org/abs/2403.19964)\] FairRAG: Fair Human Generation via Fair Retrieval Augmentation. `2024.04`
- \[[arxiv](https://arxiv.org/pdf/2406.00083v1)] BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models. `2024.06`


### Explainability
- \[[arxiv](https://arxiv.org/abs/2310.01061)\] Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning. `2024.02`
- \[[SIGIR24](https://dl.acm.org/doi/pdf/10.1145/3626772.3657660)\] RAG-Ex: A Generic Framework for Explaining Retrieval Augmented Generation. `2024.07`
- \[[arxiv](https://arxiv.org/abs/2407.20990)] From Feature Importance to Natural Language Explanations Using LLMs with RAG. `2024.06`
- \[[SIGIR24](https://dl.acm.org/doi/abs/10.1145/3626772.3657984)] IR-RAG@ SIGIR24: Information Retrieval's Role in RAG Systems. `2024.07`
- \[[arxiv](https://arxiv.org/pdf/2405.13000)] RAGE Against the Machine: Retrieval-Augmented LLM Explanations. `2024.05`

### Accountability
- \[[arxiv](https://arxiv.org/abs/2312.07913)\] A Survey of Text Watermarking in the Era of Large Language Models. `2023.12`
- \[[EMNLP24](https://aclanthology.org/2024.findings-emnlp.541)\]CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code. `2024.11`
- \[[NAACL24](https://aclanthology.org/2024.naacl-long.226)\]SEMSTAMP: A Semantic Watermark with Paraphrastic Robustness for Text Generation. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2306.04634)\]On the Reliability of Watermarks for Large Language Models. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2312.04469)\]On the Learnability of Watermarks for Language Models. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2310.18491)\]Publicly-Detectable Watermarking for Language Models. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2410.03537)\]Ward: Provable RAG Dataset Inference via LLM Watermarks. `2024.10`

### Others (Benchmarks, etc.)
- \[[arxiv](https://arxiv.org/abs/2406.05794)\] RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2401.00396)\] RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models. `2024.05`
- \[[ACL24](https://aclanthology.org/2024.acl-long.83/)\] WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models. `2024.08`

## Contribution
### üë• Contributors (üó£Ô∏è We don't have any yet but once you contribute your profile will be shown here!)
<a href="https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation" />
</a>

### üéâ Contributing ( welcome ! )
- ‚ú® Add a new paper or update an existing one.
- üßê Use the same format as existing entries to describe the work.
- üòÑ A very brief explanation why you think a paper should be added or updated is recommended (Not Neccessary) via **`Adding Issues`** or **`Pull Requests`**.

**Don't worry if you put something wrong, they will be fixed for you. Just feel free to contribute and promote your awesome work here! ü§© We'll get back to you in time ~ üòâ**

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation&type=Date)](https://star-history.com/#Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation&Date)
