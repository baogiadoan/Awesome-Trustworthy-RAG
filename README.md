# Awesome Trustworthy Retrieval Augmented Generation (RAG)
[![Awesome](https://awesome.re/badge.svg)](https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation/blob/main/LICENSE)
![](https://img.shields.io/badge/PRs-Welcome-red) 

> "The simple believes everything, but the prudent gives thought to his steps."

üôå This repository collects papers investigating the trustworthiness of retrieval augmented generation.

üòé Welcome to recommend missing papers through **`Adding Issues`** or **`Pull Requests`**. 

<!-- Details of summary and classification of papers are shown in [wiki](https://github.com/zjukg/KG-LLM-Papers/wiki). -->

## üîî News
- **`2025-06` Updated new papers!**
- **`2025-02` Our latest survey [Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2502.06872) is available on ArXiv!**
- **`2024-06` We create this repository to maintain a paper list on `Trustworthiness of the LLM Retrieval Augmented Generation paradigm`.**

<!--
*Todo:*
1. - [ ] `Fine-grained classification of papers`
2. - [ ] `Update paper project / code`
3. - [ ] `Wiki page for brief paper introduction`
-->
   
## Content

- [üìú Papers](#papers)
  - [üìù Surveys](#surveys)
    - [RAG](#rag)
    - [LLM Trustworthiness](#llm-trustworthiness)
    - [RAG Trustworthiness](#rag-trustworthiness)
  - [üîí Privacy](#privacy)
  - [üîß Reliability](#reliability)
  - [üí™ Robustness](#robustness)
  - [‚õ® Safety](#safety)
  - [‚öñÔ∏è Fairness](#fairness)
  - [üìñ Explainability](#explainability)
  - [üñäÔ∏è Accountability](@accountability)
  - [ü§ñ Others](#others)
---
##  Papers

### Surveys
#### RAG
- \[[arxiv](https://arxiv.org/abs/2312.10997)\]\[[Github](https://github.com/Tongji-KGLLM/RAG-Survey)\] Retrieval-Augmented Generation for Large Language Models: A Survey. `2024.03`
- \[[arxiv](https://arxiv.org/abs/2405.07437)\] Evaluation of Retrieval-Augmented Generation: A Survey. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2311.07914)\] Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey. `2023.11`
- \[[arxiv](https://arxiv.org/abs/2310.07521)\] Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity. `2023.10`
- \[[arxiv](https://arxiv.org/pdf/2306.11489.pdf)\] ChatGPT is not Enough: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. `2023.06`
- \[[arxiv](https://arxiv.org/abs/2211.05994)\] A Survey of Knowledge-Enhanced Pre-trained Language Models. `2023.05`
- \[[Paper](https://arxiv.org/abs/2302.07842)\] Augmented Language Models: a Survey. `2023.02`

#### LLM Trustworthiness
- \[[arxiv](https://arxiv.org/abs/2306.11698)\]\[[Website](https://decodingtrust.github.io)\] DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2304.08979)\] In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. `2023.04`
- \[[arxiv](https://arxiv.org/abs/2303.00293)\] How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks. `2023.03`
- \[[Paper](https://arxiv.org/abs/2210.09150)\] \[[Github](https://github.com/NoviScl/GPT3-Reliability)\] Prompting GPT-3 To Be Reliable. `2022.10`
#### RAG Trustworthiness
- \[[arxiv](https://arxiv.org/abs/2502.06872)\]Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey. `2025.02`
- \[[arxiv](https://arxiv.org/pdf/2409.10102)\] Trustworthiness in Retrieval-Augmented Generation Systems: A Survey. `2024.09`
- \[[arxiv](https://arxiv.org/abs/2401.05561)\] TrustLLM: Trustworthiness in Large Language Models. `2024.09`

### Privacy 
- \[[arxiv](https://arxiv.org/abs/2412.19291)\] RAG with Differential Privacy. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2412.04697)\] Privacy-Preserving Retrieval Augmented Generation with Differential Privacy. `2024.12`
- \[[arxiv](https://arxiv.org/abs/2412.12775)\] RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service. `2024.12`
- \[[arxiv](https://arxiv.org/abs/2411.01705)\] Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors. `2024.11`
- \[[arxiv](https://arxiv.org/abs/2411.14110)\] RAG-Thief: Scalable Extraction of Private Data from Retrieval-Augmented Generation Applications with Agent-based Attacks. `2024.11`
- \[[arxiv](https://arxiv.org/abs/2410.20142)\] Mask-based Membership Inference Attacks for Retrieval-Augmented Generation. `2024.10`
- \[[arxiv](https://arxiv.org/pdf/2405.20485)\] Phantom: General Trigger Attacks on Retrieval Augmented Language Generation. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2409.08045)\] Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking. `2024.09`
- \[[arxiv](https://arxiv.org/abs/2405.20446)\] Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2406.14773)\] Mitigating the Privacy Issues in Retrieval-Augmented Generation (RAG) via Pure Synthetic Data. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2305.14888)\] Privacy Implications of Retrieval-Based Language Models. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2402.16893)\] The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG). `2024.02`

### Reliability
- \[[AAAI](https://arxiv.org/abs/2410.08985v2)\] Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2408.08248)] Conformalized Answer Set Prediction for Knowledge Graph Embedding. `2024.08`
- \[[ICLR](https://arxiv.org/abs/2306.10193)\] Conformal Language Modeling. `2024.06`
- \[[arxiv](https://arxiv.org/pdf/2307.04642)\] TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction. `2024.04`
- \[[arxiv](https://proceedings.neurips.cc/paper_files/paper/2022/file/8a0d3ae989a382ce6e50312bc35bf7e1-Paper-Conference.pdf)\] Unsupervised Cross-Task Generalization via Retrieval Augmentation. `2022.04`
- \[[arxiv](https://arxiv.org/pdf/2009.08553)\] Generation-Augmented Retrieval for Open-Domain Question Answering. `2021.05`
- \[[ICML](https://arxiv.org/abs/2402.03181)\] C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models. `2024.02` 
- \[[arxiv](https://arxiv.org/abs/2404.04287)\] CONFLARE: CONFormal LArge language model REtrieval. `2024.04`

### Robustness
- \[[RAGSynth](https://arxiv.org/abs/2505.10989)\] RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization. `2025.05`
- \[[ACL](https://arxiv.org/abs/2410.07176v2)\] Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models. `2025.05`
- \[[arxiv](https://arxiv.org/abs/2502.16101)\] Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals. `2025.05`
- \[[arxiv](https://arxiv.org/abs/2504.04062)\] QE-RAG: A Robust Retrieval-Augmented Generation Benchmark for Query Entry Errors. `2025.04`
- \[[arxiv](https://arxiv.org/abs/2503.05587)\] Quantifying the Robustness of Retrieval-Augmented Language Models Against Spurious Features in Grounding Data. `2025.03`
- \[[arxiv](https://arxiv.org/abs/2502.11400)\] Revisiting Robust RAG: Do We Still Need Complex Robust Training in the Era of Powerful LLMs? `2025.02`
- \[[EMNLP](https://arxiv.org/abs/2407.13998)\] RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2410.07176)\] Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2406.00944)\] Unveil the Duality of Retrieval-Augmented Generation: Theoretical Analysis and Practical Solution. `2024.06`
- \[[ACL](https://arxiv.org/abs/2405.20978)\]  Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2405.15556)\] Certifiably Robust RAG against Retrieval Corruption. `2024.05`
- \[[ICLR](https://openreview.net/forum?id=ZS4m74kZpH)\] Making Retrieval-Augmented Language Models Robust to Irrelevant Context. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2403.14952)\] Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation. `2024.03`
- \[[LREC-COLING](https://arxiv.org/abs/2402.14409)\] Tug-of-War Between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2310.00935)\] Resolving Knowledge Conflicts in Large Language Models. `2023.10`
- \[[Paper](https://openreview.net/pdf?id=XwnABAdH5y)\] Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning. `2023.07`

### Safety 
- \[[arxiv](https://arxiv.org/abs/2504.18041)\] RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models. `2025.04`
- \[[arxiv](https://openreview.net/forum?id=2aL6gcFX7q)\] Understanding Data Poisoning Attacks for RAG: Insights and Algorithms. `2025.01`
- \[[WWW](https://openreview.net/forum?id=bwnWs4us0x#discussion)\] Traceback of Poisoned Texts in Poisoning Attacks to Retrieval-Augmented Generation. `2025.02`
- \[[arxiv](https://arxiv.org/abs/2501.02968)\] FlipedRAG: Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2501.14050)\] GraphRAG under Fire. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2501.00879)\] TrustRAG: Enhancing Robustness and Trustworthiness in RAG. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2501.11759)\] Poison-RAG: Adversarial Data Poisoning Attacks on Retrieval-Augmented Generation in Recommender Systems. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2411.18948)\] RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis. `2024.11`
- \[[ACL](https://aclanthology.org/2024.emnlp-main.610/)\] ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented Generator. `2024.11`
- \[[EMNLP](https://arxiv.org/abs/2404.13948)] Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations. `2024.10`
- \[[Usenix Security](https://arxiv.org/pdf/2402.07867)\][Github](https://github.com/sleeepeer/PoisonedRAG?tab=readme-ov-file) PoisonedRAG: Knowledge Corruption Attacks to Retrieval-Augmented Generation of Large Language Models. `2024.08`
- \[[arxiv](https://arxiv.org/pdf/2406.00083v1)\] BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models. `2024.06`
- \[[arxiv](https://arxiv.org/html/2406.18122v1)\] Poisoned LangChain: Jailbreak LLMs by LangChain. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2402.08416)\] Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2402.13532)\] Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2310.19156)\] Poisoning Retrieval Corpora by Injecting Adversarial Passages. `2023.10` 

### Fairness
- \[[arxiv](https://arxiv.org/abs/2505.17118)\] After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG. `2025.05`
- \[[WWW](https://dl.acm.org/doi/abs/10.1145/3701716.3716885?casa_token=-c_YurlvjxsAAAAA:gvvWsAYJCcZfFgXio51dEwQWzPhRyn0kVbyPSGQAb-d-l1AvN0kqbN9qkMj_o1Y5BRkXac24wBnNa4g)\] Bias-Aware Agent: Enhancing Fairness in AI-Driven Knowledge Retrieval. `2025.05`
- \[[arxiv](https://arxiv.org/abs/2506.11415)\] Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs. `2025.06`
- \[[arxiv](https://arxiv.org/abs/2504.12323)\] The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation. `2025.04`
- \[[arxiv](https://arxiv.org/abs/2502.17390)\] Mitigating Bias in RAG: Controlling the Embedder. `2025.02`
- \[[arxiv](https://arxiv.org/abs/2410.07589)\] No Free Lunch: Retrieval-Augmented Generation Undermines Fairness in LLMs, Even for Vigilant Users. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2409.11598)\] Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation. `2024.09`
- \[[arxiv](https://arxiv.org/abs/2409.19804)\] Does RAG Introduce Unfairness in LLMs? Evaluating Fairness in Retrieval-Augmented Generation Systems. `2024.09`
- \[[arxiv](https://arxiv.org/pdf/2406.00083v1)] BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2403.19964)\] FairRAG: Fair Human Generation via Fair Retrieval Augmentation. `2024.04`
- \[[arxiv](https://arxiv.org/abs/2305.19329)] Mitigating Test-Time Bias for Fair Image Retrieval. `2023.05`


### Explainability
- \[[arxiv](https://arxiv.org/abs/2310.01061)\] Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning. `2024.02`
- \[[SIGIR24](https://dl.acm.org/doi/pdf/10.1145/3626772.3657660)\] RAG-Ex: A Generic Framework for Explaining Retrieval Augmented Generation. `2024.07`
- \[[arxiv](https://arxiv.org/abs/2407.20990)] From Feature Importance to Natural Language Explanations Using LLMs with RAG. `2024.06`
- \[[SIGIR24](https://dl.acm.org/doi/abs/10.1145/3626772.3657984)] IR-RAG@ SIGIR24: Information Retrieval's Role in RAG Systems. `2024.07`
- \[[arxiv](https://arxiv.org/pdf/2405.13000)] RAGE Against the Machine: Retrieval-Augmented LLM Explanations. `2024.05`

### Accountability
- \[[arxiv](https://arxiv.org/abs/2312.07913)\] A Survey of Text Watermarking in the Era of Large Language Models. `2023.12`
- \[[EMNLP24](https://aclanthology.org/2024.findings-emnlp.541)\]CODEIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code. `2024.11`
- \[[NAACL24](https://aclanthology.org/2024.naacl-long.226)\]SEMSTAMP: A Semantic Watermark with Paraphrastic Robustness for Text Generation. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2306.04634)\]On the Reliability of Watermarks for Large Language Models. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2312.04469)\]On the Learnability of Watermarks for Language Models. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2310.18491)\]Publicly-Detectable Watermarking for Language Models. `2025.01`
- \[[arxiv](https://arxiv.org/abs/2410.03537)\]Ward: Provable RAG Dataset Inference via LLM Watermarks. `2024.10`
- \[[arxiv](https://arxiv.org/abs/2407.20990)\] From Feature Importance to Natural Language Explanations Using LLMs with RAG. `2024.06`
- \[[SIGIR24](https://dl.acm.org/doi/abs/10.1145/3626772.3657984)\] IR-RAG@ SIGIR24: Information Retrieval's Role in RAG Systems. `2024.07`

### Others (Benchmarks, etc.)
- \[[arxiv](https://arxiv.org/abs/2406.05794)\] RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2401.00396)\] RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models. `2024.05`
- \[[ACL24](https://aclanthology.org/2024.acl-long.83/)\] WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models. `2024.08`

## Contribution
### üë• Contributors 
<a href="https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation" />
</a>

### üéâ Contributing ( welcome ! )
- ‚ú® Add a new paper or update an existing one.
- üßê Use the same format as existing entries to describe the work.
- üòÑ A very brief explanation why you think a paper should be added or updated is recommended (Not Neccessary) via **`Adding Issues`** or **`Pull Requests`**.

**Don't worry if you put something wrong, they will be fixed for you. Just feel free to contribute and promote your awesome work here! ü§© We'll get back to you in time ~ üòâ**

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation&type=Date)](https://star-history.com/#Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation&Date)
